/**
 * AarogyaVani – ONNX Inference Service
 * ======================================
 * Loads the pill detection ONNX model (YOLOv8n-seg) and runs inference
 * on a base64-encoded image. Returns detected pills with class, confidence,
 * and bounding box coordinates.
 *
 * The model file must be placed at: public/models/pill_detection.onnx
 * (generated by model/export_onnx.py after training)
 */

import * as ort from 'onnxruntime-web';

export interface Detection {
    classId: number;
    className: string;
    confidence: number;
    bbox: [number, number, number, number]; // [x1, y1, x2, y2] normalised 0–1
}

export interface DetectionResult {
    detections: Detection[];
    count: number;
    imageWidth: number;
    imageHeight: number;
    inferenceTimeMs: number;
}

const MODEL_URL = '/models/pill_detection.onnx';
const INPUT_SIZE = 640;   // YOLOv8 default imgsz
const CONF_THRESHOLD = 0.45;
const IOU_THRESHOLD = 0.45;

let session: ort.InferenceSession | null = null;

/** Check if model file actually exists (not just Vite's SPA HTML fallback) */
async function modelFileExists(): Promise<boolean> {
    try {
        const res = await fetch(MODEL_URL, { cache: 'no-store' });
        const contentType = res.headers.get('content-type') ?? '';
        // Vite SPA fallback returns text/html for missing files with status 200
        return res.ok && !contentType.includes('text/html');
    } catch {
        return false;
    }
}

/** Load and cache the ONNX session */
async function getSession(): Promise<ort.InferenceSession> {
    if (!session) {
        if (!(await modelFileExists())) {
            throw new Error('MODEL_NOT_FOUND');
        }
        try {
            session = await ort.InferenceSession.create(MODEL_URL, {
                executionProviders: ['wasm'],
            });
        } catch {
            session = null;
            throw new Error('MODEL_NOT_FOUND');
        }
    }
    return session;
}

/** Pre-process: decode base64 → ImageData → Float32 tensor [1,3,640,640] */
async function imageToTensor(base64: string): Promise<{ tensor: ort.Tensor; origW: number; origH: number }> {
    return new Promise((resolve, reject) => {
        const img = new Image();
        img.onload = () => {
            const canvas = document.createElement('canvas');
            canvas.width = INPUT_SIZE;
            canvas.height = INPUT_SIZE;
            const ctx = canvas.getContext('2d')!;
            ctx.drawImage(img, 0, 0, INPUT_SIZE, INPUT_SIZE);

            const { data } = ctx.getImageData(0, 0, INPUT_SIZE, INPUT_SIZE);
            const float32 = new Float32Array(3 * INPUT_SIZE * INPUT_SIZE);

            // HWC → CHW, normalise to [0, 1]
            for (let i = 0; i < INPUT_SIZE * INPUT_SIZE; i++) {
                float32[i] = data[i * 4] / 255; // R
                float32[i + INPUT_SIZE * INPUT_SIZE] = data[i * 4 + 1] / 255; // G
                float32[i + 2 * INPUT_SIZE * INPUT_SIZE] = data[i * 4 + 2] / 255; // B
            }

            resolve({
                tensor: new ort.Tensor('float32', float32, [1, 3, INPUT_SIZE, INPUT_SIZE]),
                origW: img.naturalWidth,
                origH: img.naturalHeight,
            });
        };
        img.onerror = reject;
        img.src = `data:image/jpeg;base64,${base64}`;
    });
}

/** Non-Maximum Suppression */
function nms(boxes: number[][], scores: number[], iouThresh: number): number[] {
    const order = scores.map((_, i) => i).sort((a, b) => scores[b] - scores[a]);
    const keep: number[] = [];

    while (order.length) {
        const i = order.shift()!;
        keep.push(i);
        const filtered = order.filter(j => {
            const [x1, y1, x2, y2] = boxes[i];
            const [bx1, by1, bx2, by2] = boxes[j];
            const ix1 = Math.max(x1, bx1), iy1 = Math.max(y1, by1);
            const ix2 = Math.min(x2, bx2), iy2 = Math.min(y2, by2);
            const inter = Math.max(0, ix2 - ix1) * Math.max(0, iy2 - iy1);
            const union = (x2 - x1) * (y2 - y1) + (bx2 - bx1) * (by2 - by1) - inter;
            return inter / union < iouThresh;
        });
        order.splice(0, order.length, ...filtered);
    }
    return keep;
}

/** 
 * Run pill detection on a base64 image.
 * Requires public/models/pill_detection.onnx to exist (run export_onnx.py first).
 */
export async function detectPills(base64Image: string): Promise<DetectionResult> {
    const t0 = performance.now();

    // getSession() handles model-not-found check internally
    let sess: ort.InferenceSession;
    try {
        sess = await getSession();
    } catch (e: any) {
        if (e?.message === 'MODEL_NOT_FOUND') {
            throw new Error('MODEL_NOT_FOUND');
        }
        throw e;
    }
    const { tensor, origW, origH } = await imageToTensor(base64Image);

    // 2. Run inference
    const inputName = sess.inputNames[0];
    const outputs = await sess.run({ [inputName]: tensor });

    // YOLOv8 output shape: [1, num_classes+4, num_anchors]
    const output = outputs[sess.outputNames[0]];
    const data = output.data as Float32Array;
    const [, rows, anchors] = output.dims as number[];

    const boxes: number[][] = [];
    const scores: number[] = [];
    const classIds: number[] = [];

    for (let a = 0; a < anchors; a++) {
        let maxConf = 0;
        let maxClass = 0;

        for (let c = 4; c < rows; c++) {
            const conf = data[c * anchors + a];
            if (conf > maxConf) { maxConf = conf; maxClass = c - 4; }
        }

        if (maxConf < CONF_THRESHOLD) continue;

        const cx = data[0 * anchors + a] / INPUT_SIZE;
        const cy = data[1 * anchors + a] / INPUT_SIZE;
        const w = data[2 * anchors + a] / INPUT_SIZE;
        const h = data[3 * anchors + a] / INPUT_SIZE;

        boxes.push([cx - w / 2, cy - h / 2, cx + w / 2, cy + h / 2]);
        scores.push(maxConf);
        classIds.push(maxClass);
    }

    const kept = nms(boxes, scores, IOU_THRESHOLD);

    const detections: Detection[] = kept.map(i => ({
        classId: classIds[i],
        className: `Pill ${classIds[i] + 1}`,
        confidence: Math.round(scores[i] * 100) / 100,
        bbox: boxes[i] as [number, number, number, number],
    }));

    return {
        detections,
        count: detections.length,
        imageWidth: origW,
        imageHeight: origH,
        inferenceTimeMs: Math.round(performance.now() - t0),
    };
}
